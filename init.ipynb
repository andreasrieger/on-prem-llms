{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, ollama\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules import userinput\n",
    "from modules import filehandler\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, Distance, VectorParams\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# user_choice = userinput.get_user_input(\"Select file by index (0, 1, 2, ...): \", \"0\")\n",
    "# selected_file = file_list[int(user_choice)]\n",
    "selected_file = 'input/20251120-mfi-products.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "# the default file encoding type is 'utf_8', change to e.g. 'cp1252' if needed\n",
    "# the default field separator is ';', change to something else (e.g. ',') if needed\n",
    "df = filehandler.read_csv_file(selected_file)\n",
    "\n",
    "drop_columns = ['shelflife', 'CN_code', 'country_of_origin']\n",
    "\n",
    "df_temp = df.copy()\n",
    "df_temp = df_temp.drop(columns=drop_columns)\n",
    "df_temp = df_temp.rename(columns={'product_name_alias': 'title', 'product_description': 'description'})\n",
    "\n",
    "\n",
    "# Function to keep only string values and True boolean values\n",
    "def keep_string_or_true(row):\n",
    "    kept = {}\n",
    "    for col, val in row.items():\n",
    "        if pd.isna(val):\n",
    "            continue\n",
    "        if isinstance(val, str):\n",
    "            if val.strip() != \"\":\n",
    "                kept[col] = val\n",
    "        elif val is True:\n",
    "            kept[col] = val\n",
    "    return json.dumps(kept)\n",
    "\n",
    "# Add a column with per-row dict of kept values\n",
    "df_temp['json_data'] = df_temp.apply(keep_string_or_true, axis=1)\n",
    "\n",
    "\n",
    "# Option A: keep the dicts (one cell per row)\n",
    "# filtered_series = df_temp['filtered']\n",
    "\n",
    "# Option B: expand dicts back to columns (sparse; missing entries become NaN)\n",
    "# filtered_df = pd.json_normalize(filtered_series).reindex(df_temp.index)\n",
    "\n",
    "# If you want df_temp to be the expanded result uncomment:\n",
    "# df_temp = filtered_df\n",
    "\n",
    "\n",
    "keep_columns = ['title', 'description', 'json_data']\n",
    "df_temp = df_temp[keep_columns]\n",
    "\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embeddings(o, m):\n",
    "    # model = \"mxbai-embed-large\" # byte size of vector is 8248\n",
    "    return ollama.embeddings(m, o)[\"embedding\"]\n",
    "\n",
    "\n",
    "df_temp['embedding'] = df_temp['json_data'].apply(lambda x: generate_embeddings(x, \"mxbai-embed-large\"))\n",
    "# df_temp.head(-3)\n",
    "\n",
    "measurer = np.vectorize(len)\n",
    "\n",
    "vector_size = measurer(df_temp['embedding']).max(axis=0)\n",
    "# print(f\"Embedding vector size: {vector_size}\")\n",
    "# print(f\"Embedding vector sizes: min={vector_size.min()}, max={vector_size.max()}, mean={vector_size.mean()}\")\n",
    "\n",
    "\n",
    "# Create a collection\n",
    "collection_name = \"products_collection\"\n",
    "payload = [\"title\", \"description\"]\n",
    "\n",
    "\n",
    "def prepare_data(df, payload):\n",
    "    # Prepare data for insertion\n",
    "    points = []\n",
    "    for idx, row in df.iterrows():\n",
    "        point = PointStruct(\n",
    "            id=idx,\n",
    "            vector=row['embedding'],\n",
    "            payload={\n",
    "                \"title\": row[payload[0]],\n",
    "                \"description\": row[payload[1]]\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "    return points\n",
    "\n",
    "\n",
    "# Define collection\n",
    "def define_collection(c, n, s):\n",
    "    if not c.collection_exists(n):\n",
    "        c.create_collection(\n",
    "            collection_name=n,\n",
    "            vectors_config=VectorParams(size=s, distance=Distance.COSINE)\n",
    "        )\n",
    "\n",
    "\n",
    "# Insert data into the collection\n",
    "def insert_data(c, n, p):\n",
    "    c.upsert(\n",
    "        collection_name=n,\n",
    "        points=p\n",
    "    )\n",
    "\n",
    "\n",
    "def db_init(collection_name, df, payload, vector_size):\n",
    "    # Initialize Qdrant client\n",
    "    # qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "    qdrant_client = QdrantClient(\":memory:\")\n",
    "    define_collection(qdrant_client, collection_name, vector_size)\n",
    "\n",
    "    points = prepare_data(df, payload)\n",
    "    insert_data(qdrant_client, collection_name, points)\n",
    "\n",
    "    return qdrant_client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
