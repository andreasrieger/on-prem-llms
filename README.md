# On-Prem LLMs

Utilities for running LLMs on-premises with RAG (Retrieval-Augmented Generation) and SQL agent capabilities.

## Overview

This project provides tools for building AI agents that run entirely on-premises using Ollama, Qdrant vector store, and LangChain. It includes two main agent types:

- **RAG Agent**: Query documents using vector similarity search and LLM-powered question answering
- **SQL Agent**: Interact with SQL databases through natural language queries

## Features

- ğŸ”’ Fully on-premises deployment with local LLM models (via Ollama)
- ğŸ“š Document processing and vector storage with Qdrant
- ğŸ¤– LangChain-based agent orchestration
- ğŸ’¾ SQLite database integration
- ğŸ“„ PDF document processing
- ğŸ” Semantic search capabilities

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd on-prem-llms
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Install the package in development mode:
```bash
pip install -e .
```

## Prerequisites

- Python 3.10+
- [Ollama](https://ollama.ai/) installed and running locally
- Required Ollama models:
  - `nomic-embed-text` (for embeddings)
  - `ministral-3` (for chat/completion)

Pull the models with:
```bash
ollama pull nomic-embed-text
ollama pull ministral-3
```

## Usage

### RAG Agent

Query documents using semantic search and LLM-powered answers:

```bash
python rag_agent.py
```

The RAG agent:
- Loads document chunks from a SQLite database
- Creates vector embeddings using Ollama
- Stores vectors in Qdrant (in-memory)
- Retrieves relevant context for user queries
- Generates answers with source citations

### SQL Agent

Query SQL databases using natural language:

```bash
python sql_agent.py
```

The SQL agent:
- Connects to a SQLite database
- Translates natural language to SQL queries
- Executes queries safely (read-only)
- Returns results in natural language

## Project Structure

```
on-prem-llms/
â”œâ”€â”€ src/mypackage/          # Core package modules
â”‚   â”œâ”€â”€ dbmanager.py        # Database management utilities
â”‚   â”œâ”€â”€ embedder.py         # Embedding generation
â”‚   â”œâ”€â”€ finder.py           # File and path utilities
â”‚   â”œâ”€â”€ generator.py        # Text generation utilities
â”‚   â”œâ”€â”€ knowledger.py       # Knowledge base management
â”‚   â”œâ”€â”€ preparator.py       # Data preparation
â”‚   â”œâ”€â”€ retriever.py        # Document retrieval
â”‚   â”œâ”€â”€ splitter.py         # Text chunking
â”‚   â””â”€â”€ userinput.py        # User input handling
â”œâ”€â”€ rag_agent.py            # RAG agent implementation
â”œâ”€â”€ sql_agent.py            # SQL agent implementation
â”œâ”€â”€ data/                   # Data storage directory
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”œâ”€â”€ pyproject.toml          # Package configuration
â””â”€â”€ requirements.txt        # Python dependencies
```

## Dependencies

Core dependencies include:
- `langchain` - LLM application framework
- `langchain-ollama` - Ollama integration
- `langchain-qdrant` - Qdrant vector store integration
- `qdrant-client` - Qdrant database client
- `pandas` - Data manipulation
- `SQLAlchemy` - SQL toolkit
- `pypdf` - PDF processing

## Configuration

The project uses:
- **Embedding model**: `nomic-embed-text` (768-dimensional vectors)
- **Chat model**: `ministral-3` (temperature: 0.0)
- **Vector store**: Qdrant (in-memory mode)
- **Distance metric**: Cosine similarity

## License

MIT License

## Author

Andreas Rieger (dev@rieger.digital)
